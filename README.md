# Programación sobre grandes volúmenes de datos 

## Descripción del curso
En un mundo donde “quien tiene la información tiene el poder”, se nos presenta un gran desafío y debemos estar listos para empezar afrontarlo, es un mundo donde cada vez más las decisiones se toman basados en la información y esto nos da una ventaja competitiva que sin duda puede hacer la diferencia entre el éxito y el fracaso. Es la era de la revolución de los datos, donde cada día se generan más datos que el día anterior y es justo ahí donde podemos ver una gran oportunidad.

En ese contexto se enmarca el curso de Programación de grandes volúmenes de datos, como una alternativa para afrontar el desafío que vivimos hoy con el fin de aprovechar esa gran cantidad de datos y convertirlos en conocimiento. 

Entraremos en el mundo del Big Data para conocerlo a fondo, entenderemos que ha cambiado en el mundo para que aparezcan estas nuevas alternativas y veremos con ejemplos reales que es un área transversal. En este camino nos encontramos con una nueva alternativa de programación orientada a los sistemas distribuidos y a la paralelización de los procesos.
Revisaremos Frameworks para Big Data como Hadoop y su ecosistema que nos permite pensar en un almacenamiento y procesamiento distribuido. Para luego centrar toda nuestra atención en Spark, la herramienta que utilizaremos a lo largo del curso.
Revisaremos las diferentes alternativas que nos ofrece Spark para el tratamiento de los datos como es el caso de los RDD y DataFrame, y por último nos enfocaremos en la ciencia de datos entendiendo las necesidades del Machine Learning en entornos de Big Data.

## Programación de sesiones

**SESIÓN 01: Big Data** (6hrs):
Big Data
- Las Vs del Big Data
- Escalabilidad
- Bases de datos NoSQL
- Aplicaciones de Big Data
- Frameworks para Big Data
- Ecosistema Hadoop: HDFS, Map Reduce, Hbase, Pig, Hive, entre otros 
- Spark:  Arquitectura, Clusters



**SESIÓN 02: Map Reduce en Spark** (4hrs): 
- Map Reduce
- Ejercicios Map Reduce

**SESIÓN 03: Map Reduce y RDD** (6hrs): 
- TALLER: Map Reduce
- RDD
- Ejercicios RDD

**SESIÓN 04: RDD y DataFrame** (4hrs): 
- TALLER: RDD
- DataFrame

**SESIÓN 05: DataFrame y Machine Learning** (6hrs): 
- Ejercicios DataFrame
- TALLER: DataFrame
- Machine Learning: Preparación de Datos

**SESIÓN 06: Machine Learning** (4hrs): 
- Aprendizaje Supervisado
- Aprendizaje NO Supervisado

## Criterios de evaluación
- 30%: TALLER Map Reduce
- 30%: TALLER RDD
- 40%: TALLER DataFrame

## Entregas
Las entregas del curso (informes, notebooks, etc.) se realizarán en el Drive compartido con cada estudiante. Los talleres se realizan en equipos de trabajo durante las sesiones marcadas como [TALLER], en cada sesión de talle se definirán las fechas de entrega.

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/usuario/repositorio/blob/main/archivo.ipynb)

